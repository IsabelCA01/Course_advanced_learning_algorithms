{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advice for applying machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debbuging a learning algorithm\n",
    "\n",
    "You've implemented regularized linear regression on housing prices. \n",
    "\n",
    "But it makes unacceptably large errors in predictions. What do you try next?\n",
    "\n",
    "- Get more training examples\n",
    "\n",
    "- Try smaller sets of features\n",
    "\n",
    "- Try getting additional features\n",
    "\n",
    "- Try adding polynomial features ($x_1^2, x_2^2, x_1x_2, etc$)\n",
    "\n",
    "- Try decreasing $\\lambda$\n",
    "\n",
    "- Try increasing $\\lambda$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning diagnostic\n",
    "\n",
    "A test that you can run to gain insight what is/isn't working with a learning algorithm, and gain guidance as to how best to improve its performance.\n",
    "\n",
    "- A diagnostic can take time to implement, but doing so can be a very good use of your time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For linerar regression (with squared error cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the 70% of the available data as training set, and the remaining 30% as test set. Or 80% and 20%\n",
    "\n",
    "Train the model on the training set, and evaluate it's performance on the test set.\n",
    "\n",
    "Training set: Fit parameters by minimizing cost function $J(\\vec w, b)$\n",
    "\n",
    "$$J(\\vec w, b) = (\\frac{1}{2m_{train}} \\sum^{m_{train}}_{i=1} (f\\vec w, b (\\vec x^{(i)}) - y^{(i)})^2 + \\frac {\\lambda}{2m_{train}} \\sum^n_{j=1} w^2_j$$\n",
    "\n",
    "Test set: Compute test set error\n",
    "\n",
    "$$J_{test}(\\vec w, b) = (\\frac{1}{2m_{test}} [\\sum^{m_{test}}_{i=1} (f\\vec w, b (\\vec x^{(i)}) - y^{(i)})^2]$$\n",
    "\n",
    "**Note that there is no regularization parameter in the second one.**\n",
    "\n",
    "Compute training error: \n",
    "\n",
    "$$J_{train}(\\vec w, b) = (\\frac{1}{2m_{train}} [\\sum^{m_{train}}_{i=1} (f\\vec w, b (\\vec x^{(i)}) - y^{(i)})^2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a model that fits very well the parameters, but will not generalize well to new additional data, it is called **overfitting**. \n",
    "\n",
    "- $J_{train}(\\vec w,b)$ will be low.\n",
    "\n",
    "- $J_{test}(\\vec w,b)$ will be high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit parameters by minimizing $J(\\vec w, b)$ to find $\\vec w, b$:\n",
    "\n",
    "$$J(\\vec w,b) = -\\frac{1}{m_{train}} \\sum^{m_{train}}_{i=1} [y^{(i)} \\log (f_{\\vec w,b}(\\vec x^{(i)})) + (1-y^{(i)}) \\log (1 - f_{\\vec w,b}(\\vec x^{(i)}))] + \\frac {\\lambda}{2m_{train}} \\sum^n_{j=1} wÂ²_j $$\n",
    "\n",
    "**Option 1**\n",
    "\n",
    "Compute test error:\n",
    "\n",
    "$$J_{test}(\\vec w,b) = -\\frac{1}{m_{test}} \\sum^{m_{test}}_{i=1} [y^{(i)}_{test} \\log (f_{\\vec w,b}(\\vec x^{(i)}_{test})) + (1-y^{(i)}_{test}) \\log (1 - f_{\\vec w,b}(\\vec x^{(i)}_{test}))]$$\n",
    "\n",
    "Compute training error:\n",
    "\n",
    "$$J_{train}(\\vec w,b) = -\\frac{1}{m_{train}} \\sum^{m_{train}}_{i=1} [y^{(i)}_{train} \\log (f_{\\vec w,b}(\\vec x^{(i)}_{train})) + (1-y^{(i)}_{train}) \\log (1 - f_{\\vec w,b}(\\vec x^{(i)}_{train}))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2**\n",
    "\n",
    "Instead of using the logistic loss to compute the test and train errors, we can measure what the fraction of the test set and the fraction of the training set that was misclassified.\n",
    "\n",
    "$$ \\hat y = \\{  \\begin{array}{rcl}\n",
    "1 & if & f_{\\vec w,b}(\\vec x^{(i)}) \\geq 0.5 \\\\ 0 & if & f_{\\vec w,b} (\\vec x^{(i)}) < 0.5 \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "count $\\hat y \\neq y$\n",
    "\n",
    "$J_{test}(\\vec w,b)$ is the fraction of the test set that has been misclassified.\n",
    "\n",
    "$J_{train}(\\vec w,b)$ is the fraction of the training set that has been misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and training / cross validation / test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once parameters $\\vec w,b$ are fit to the training set, the training error $J_{train}(\\vec w,b)$ is likely lower than the true generalization error $J_{test}(\\vec w,b)$.\n",
    "\n",
    "- $J_{test}(\\vec w,b)$ is better estimate on how well the model will generalize to new data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have 10 different models to choose from, we can train each of them on the training set, and evaluate the performance on the test set. Then we can choose the model that performed best on the test set (the one with the lowest $J_{test}(\\vec w,b)$).\n",
    "\n",
    "However this process is flawed because we might end up with overly optimistic estimate of the generalization error.\n",
    "\n",
    "**Cross validation**\n",
    "\n",
    "We divide our trainig set into 3 parts:\n",
    "\n",
    "- Training set: 60%\n",
    "\n",
    "- Cross validation set (validation set, development set, dev set): 20%. Used to check or cross check the validity or really the accuracy of different models.\n",
    "\n",
    "- Test set: 20%\n",
    "\n",
    "\n",
    "**Same formulas as before**\n",
    "\n",
    "Training error:\n",
    "\n",
    "$$J_{train}(\\vec w,b) = \\frac{1}{2m_{train}} [\\sum^{m_{train}}_{i=1} (f\\vec w, b (\\vec x^{(i)}) - y^{(i)})^2]$$\n",
    "\n",
    "Cross validation error:\n",
    "\n",
    "$$J_{cv}(\\vec w,b) = \\frac{1}{2m_{cv}} [\\sum^{m_{cv}}_{i=1} (f\\vec w, b (\\vec x^{(i)}) - y^{(i)})^2]$$\n",
    "\n",
    "Test error:\n",
    "\n",
    "$$J_{test}(\\vec w,b) = \\frac{1}{2m_{test}} [\\sum^{m_{test}}_{i=1} (f\\vec w, b (\\vec x^{(i)}) - y^{(i)})^2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model selection**\n",
    "\n",
    "We train each of the 10 models on the training set, and evaluate the performance on the cross validation set. Then we choose the model that performed best on the cross validation set (the one with the lowest $J_{cv}(\\vec w,b)$).\n",
    "\n",
    "Finally we evaluate the performance of the model on the test set."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
